# 기업용 sLLM 제품 기획 제안서 (초안)

## 1. 개요
본 제안서는 SI(System Integration) 사업자 모델에 맞춰, 고객사(Enterprise/Public)에게 구축형(On-Premise) 또는 프라이빗 클라우드 형태로 제공 가능한 **기업 특화 경량 언어 모델(sLLM)** 제품의 기획 초안입니다.

## 2. 제품 컨셉: "Secure & Specialized Enterprise AI"
- **핵심 가치**: 데이터 보안(폐쇄망 구동), 비용 효율성(낮은 추론 비용), 도메인 특화(업무 맞춤형)
- **타겟 시장**:
    - 금융/공공/제조: 데이터 외부 유출이 불가능한 엄격한 보안 환경
    - 글로벌 비즈니스: **한국어, 일본어, 영어** 3개 국어 능통한 업무 보조 (매뉴얼 번역, 크로스보더 커뮤니케이션)

## 3. 베이스 모델 선정 전략 (다국어 특화)
고객사의 요구사항인 **한국어, 일본어, 영어** 동시 지원을 위해, 해당 언어들의 사전학습 데이터 비율이 높고 벤치마크 성능이 우수한 모델을 최우선으로 고려합니다.

### 추천 베이스 모델 후보 (2025 sLLM 기준)
| 모델명 | 파라미터 | 라이선스 | 다국어(KR/JP/EN) 능력 | 추천 등급 |
| :--- | :--- | :--- | :--- | :--- |
| **Qwen 2.5** | 7B / 14B | Apache 2.0 | **최상**. 영어/중국어 기반이나 일본어/한국어 성능이 동급 오픈소스 중 압도적임. | **1순위** |
| **Llama 3.1** | 8B | Community | **우수**. 영어는 최상이나, 한국어/일본어는 별도 튜닝 없이는 문체나 뉘앙스 처리가 다소 딱딱할 수 있음. | 2순위 |
| **Gemma 2** | 9B | Gemma Terms | **양호**. 구글의 다국어 데이터셋 강점 보유. 일본어 성능 준수함. | 3순위 |
| **Solar-10.7B** | 10.7B | Apache 2.0 | **조건부**. 한국어/영어는 매우 뛰어나나, 일본어 학습 데이터 비중 확인 필요. | 검토 필요 |

> **최종 제안**: **Qwen 2.5 (14B 또는 7B)**
> - **이유**: Apache 2.0으로 2차 저작물 상업적 판매가 매우 자유로우며, 벤치마크상 **일본어 및 한국어 성능이 7B~14B 체급에서 가장 뛰어남**.
> - **대안**: 고객사가 '중국 계열 모델'에 거부감이 심할 경우, **Llama 3.1**을 베이스로 하되 한국어/일본어 코퍼스를 추가 학습(CPT)하는 방향 선회.

## 4. 기술 아키텍처 (High-Level)

### A. 학습 파이프라인 (The Tuning Factory) - "Kelron의 지능을 만드는 곳"
**한국어/일본어/영어** 3개 국어 데이터의 밸런싱과 **Kelron 아이덴티티** 확립이 핵심입니다.
- **Fine-tuning**:
    - **Identity**: "저는 Kelron입니다" 자아 인식 학습
    - **Instruction**: 3개 국어 명령 수행 능력 배양 (번역, 요약 등)

### B. 검색 증강 생성, RAG (The Knowledge Library) - "파일을 읽고 답하는 능력"
모델 재학습 없이 PDF나 문서를 즉시 읽고 답변하려면 **RAG(Retrieval-Augmented Generation)** 시스템이 필수입니다.
1.  **Document Parser**: PDF, HWP, Word 내의 텍스트와 표를 추출 (OCR 포함)
2.  **Vector Store**: 추출된 텍스트를 숫자로 변환(Embedding)하여 저장
3.  **Retriever**: 사용자가 질문하면 관련 내용을 찾아 Kelron에게 전달
    *   *Kelron은 이 전달받은 내용을 바탕으로 답변을 작성합니다.*

### C. 서빙 및 애플리케이션 (The Product)
- **Inference Engine**: **vLLM** 또는 **TGI**를 사용하여 처리량(Throughput) 극대화 (약 24GB VRAM GPU 1장으로도 구동 가능하게 최적화)
- **RAG System**: 기업 내부 문서를 벡터화하여 모델이 참조할 수 있게 하는 검색 증강 생성 모듈 필수 포함
- **LLM Ops**: 모델 버전 관리 및 배포 자동화

## 5. 단계별 추진 로드맵

### Phase 1: 다국어 프로토타입 & Identity (1개월)
- [ ] **Qwen 2.5 (or Llama 3.1)** 베이스 모델 선정
- [ ] **Kelron 자아 인식(Identity)** 데이터셋 구축 및 학습 (Self-Cognition)
- [ ] 한/일/영 3개 국어 기본 Instruction 데이터셋(약 10k set) 구축 및 튜닝
- [ ] 3개 국어 교차 번역 및 질의응답 성능 테스트

### Phase 2: 도메인 특화 및 RAG 검증 (2개월)
- [ ] 다국어 문서(PDF, Office) 파싱 및 임베딩 구축
- [ ] **일본어/한국어 형태소 분석기**를 결합한 하이브리드 검색(RAG) 구현
- [ ] 언어별 답변 정확도 및 Tone & Manner 튜닝

### Phase 3: 제품 패키징 (3개월~)
- [ ] 설치형 솔루션(Docker/Kubernetes) 패키징
- [ ] 관리자 페이지(프롬프트 관리, 사용자 로그 분석) 개발
- [ ] GS인증 등 소프트웨어 품질 인증 준비

## 6. 온프라미스 납품 및 운영 전략 (Lifecycle)
고객사 서버실에 직접 설치하는 온프라미스 특성상, **사전 준비부터 유지보수까지 완벽한 매뉴얼**이 필요합니다.

### A. 납품 전 (Pre-Delivery) - "요구사항 확정 및 하드웨어 준비"
- **하드웨어 스펙 가이드 제공**: 동시 접속자 수에 따른 GPU 서버 사양 권고 (예: RTX 4090 x 2 or A100 x 1)
- **보안/네트워크 사전 체크**: 폐쇄망 여부, 외부 인터넷 차단 시 Docker Image 오프라인 이관 계획 수립
- **데이터 반출입 절차 협의**: 학습에 필요한 고객사 데이터의 보안 반출 가능 여부 확인 (불가 시 고객사 파견 튜닝 필요)

### B. 납품 시 (Delivery & Installation) - "설치 및 검증"
- **원클릭 설치 패키지**: `docker-compose up` 수준의 간편한 설치 스크립트 제공
- **현장 성능 테스트 (FAT)**: 설치 직후 3개 국어(한/일/영) 답변 속도 및 RAG 검색 정확도 현장 시연
- **운영자 교육**: 사내 IT 담당자 대상 모델 재기동, 로그 확인, 프롬프트 수정 방법 교육

### C. 납품 후 (Post-Delivery) - "유지보수 및 고도화"
- **정기 업데이트**: 최신 보안 패치 및 모델 성능 개선 버전(v1.1, v1.2) 정기 제공 (USB/망연계 솔루션 활용)
- **장애 대응 (SLA)**: 서버 다운 시 원격 지원 또는 긴급 출동 체계(유지보수 계약 포함)
- **Model Drift 관리**: 데이터 최신화가 필요할 때마다 재학습(Re-training) 파이프라인 가동 가이드

## 7. 논의 필요 사항 (Decision Points)
1. **타겟 하드웨어 스펙**: 고객사에 권장할 최소 사양 (예: NVIDIA A10/L40S 또는 저가형 RTX 4090 등)
2. **비즈니스 모델**: 구축비(일회성) + 유지보수(연간) 구조인지, 구독형인지 결정
3. **특화 분야**: "모든 것을 다 하는 챗봇"보다는 "사내 규정 전문", "계약서 검토 전문" 등 구체적 유즈케이스 선정 필요
4. **라이선스/브랜드 전략**: 기술적으로는 **Kelron**이 Qwen임을 모르게 완벽히 숨길 수 있으나(Identity Tuning), **Apache 2.0 라이선스**상 제품 정보 어딘가(About 페이지 등)에는 원작자(Qwen Project) 표기가 필요합니다. 이 부분 노출 수위를 결정해야 합니다.

---
이 초안을 바탕으로 귀사의 강점이나 구상하고 계신 방향에 맞춰 수정해 드리겠습니다. 특히 **특정 산업군(금융, 공공 등)**을 염두에 두고 계시다면 말씀해 주세요.
