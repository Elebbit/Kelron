# Kelron - Sovereign LLM Identity Layer

Kelronì€ Qwen 2.5-14B ê¸°ë°˜ì˜ fine-tuned LLMìœ¼ë¡œ, ë…ìì ì¸ AI ì •ì²´ì„±ì„ ê°€ì§„ ëŒ€í™”í˜• AIì…ë‹ˆë‹¤.

## ğŸ¯ Project Goal

- **Phase 1**: Identity Infusion (ì •ì²´ì„± ì£¼ì…)
- **Phase 2**: Safety & Ethics Training
- **Phase 3**: Domain Expertise Enhancement

## ğŸ“ Structure

```
Kelron/
â”œâ”€â”€ notebooks/          # Kaggle training scripts
â”‚   â”œâ”€â”€ kelron_config.py        # Configuration
â”‚   â”œâ”€â”€ step1_install.py        # Dependencies
â”‚   â”œâ”€â”€ step2_test.py           # Environment test
â”‚   â”œâ”€â”€ step3_train.py          # QLoRA training
â”‚   â”œâ”€â”€ step4_test_identity.py  # Identity verification
â”‚   â””â”€â”€ step5_merge.py          # Adapter merge
â”œâ”€â”€ data/               # Training datasets
â””â”€â”€ technical_log.md    # GPU debugging history
```

## ğŸ”§ Training Environment

- **Model**: Qwen 2.5-14B-Instruct (Int4 Quantization)
- **Hardware**: Kaggle Dual T4 GPU (15GB x 2)
- **Method**: QLoRA Fine-tuning

## ğŸ“ Key Learnings

Multi-GPU í•™ìŠµ ì‹œ í•µì‹¬ ì „ëµ (10ë²ˆì˜ ì‹œë„ ëì— ê²€ì¦ë¨):
- **I/O ëª¨ë“ˆ (embed_tokens, lm_head)ëŠ” GPU 0ì— ê³ ì •**
- **ì—°ì‚° ë ˆì´ì–´ë§Œ GPU 1ë¡œ ë¶„ì‚°**
- `prepare_model_for_kbit_training()` í•„ìˆ˜

ìì„¸í•œ ë‚´ìš©ì€ `technical_log.md` ì°¸ì¡°.

## ğŸš€ Status

- [x] Phase 1 Training (In Progress - ~16.5h remaining)
