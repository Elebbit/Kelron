import torch
import gc
import os
from transformers import AutoModelForCausalLM, AutoTokenizer
from peft import PeftModel
# [NEW] Shared Configuration
from kelron_config import MODEL_ID as BASE_MODEL, ADAPTER_PATH

# 1. ì„¤ì •
MERGED_MODEL_DIR = "/kaggle/working/kelron_14b_standalone" if os.path.exists("/kaggle") else "/Users/ohe/Projects/Kelron/outputs/kelron_14b_standalone"

print(f"ðŸ”¨ [Processing] Merging Adapter into Base Model...")
print(f"   - Base: {BASE_MODEL}")
print(f"   - Adapter: {ADAPTER_PATH}")
print(f"   - Output: {MERGED_MODEL_DIR}")

# ë©”ëª¨ë¦¬ ì •ë¦¬
gc.collect()
torch.cuda.empty_cache()

# 2. ë² ì´ìŠ¤ ëª¨ë¸ ë¡œë“œ (CPU or GPU)
# ë³‘í•© ìž‘ì—…ì„ ìœ„í•´ì„  4bit ì–‘ìží™”ê°€ ì•„ë‹Œ, fp16ì´ë‚˜ bf16ìœ¼ë¡œ ë¡œë“œí•´ì•¼ ë³‘í•©ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.
# T4 x2 í™˜ê²½ì—ì„œëŠ” ë©”ëª¨ë¦¬ê°€ ë¶€ì¡±í•  ìˆ˜ ìžˆìœ¼ë¯€ë¡œ, device_map="cpu"ë¡œ ë¡œë“œ í›„ ë³‘í•©í•˜ê±°ë‚˜
# í˜¹ì€ High-RAM í™˜ê²½ì´ í•„ìš”í•©ë‹ˆë‹¤. (ì—¬ê¸°ì„  ì¼ë°˜ì ì¸ ë³‘í•© ì½”ë“œ ì œì‹œ)
try:
    print("   ... Loading Base Model (may take time)...")
    base_model = AutoModelForCausalLM.from_pretrained(
        BASE_MODEL,
        torch_dtype=torch.float16,
        device_map="auto", # T4 x2ì—ì„œëŠ” ë¶„ì‚° ë¡œë“œ
        trust_remote_code=True
    )
    
    tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, trust_remote_code=True)
    
    # 3. ì–´ëŒ‘í„° ë¡œë“œ ë° ë³‘í•©
    print("   ... Loading Adapter and Merging...")
    model = PeftModel.from_pretrained(base_model, ADAPTER_PATH)
    
    # [í•µì‹¬] ë³‘í•© ì‹¤í–‰
    merged_model = model.merge_and_unload()
    
    # 4. ì €ìž¥
    print(f"ðŸ’¾ Saving Standalone Model to {MERGED_MODEL_DIR}...")
    merged_model.save_pretrained(MERGED_MODEL_DIR)
    tokenizer.save_pretrained(MERGED_MODEL_DIR)
    
    print(f"\nðŸŽ‰ SUCCESS: 'Kelron' is now a standalone model!")
    print(f"   You can now load this model directly without Qwen base.")

except Exception as e:
    print(f"\nâŒ Merge Failed (likely OOM): {e}")
    print("   Tip: Merging 14B models requires substantial RAM (>60GB).")
    print("   If running on limited hardware, consider 'Adapter-only' deployment or use cloud instances for merging.")
